이번 장에서는 가중치 매개변수의 최적값을 탐색하는 최적화와 가중치 매개변수 초깃값과 하이퍼파라미터를 설정하는 방법에 대해 설명 드리겠습니다.

신경망 학습의 목적은 손실 함수의 값을 최대한 낮추는 매개변수의 최적값을 찾는 것인데 신경망의 최적화는 매우 어려운 문제고, 또 심층 신경망으로 갈수록 매개변수의 수가 엄청나게 많아져서 정답을 찾기는 거의 불가능합니다.

다음은 교재에서 인상 깊었던 예시인데요. 본론으로 들어가기 전에 먼저 말씀드리겠습니다.

색다른 모험가가 있습니다. 광활하고 메마른 산맥을 여행하면서 가장 깊고 깊은 골짜기를 찾아가려 합니다. 그런데 심지어 엄격한 제약이 있습니다. 지도를 보지 않고 눈도 가리고 깊은 곳을 찾아가야 합니다. 눈이 보이지 않으니 믿을 거라곤 발바닥으로 느껴지는 기울기뿐입니다. 지금 서 있는 곳보다 조금 더 기울어진 곳을 찾아 천천히 걸음을 옮기는 수밖에 없습니다.

우리도 최적값을 찾기 위해 이 모험가처럼 손실 함수가 가장 낮은 방향으로 매개변수를 조정해 나가야 합니다. 매우 어려운 문제입니다.

그래도  가장 깊거나 가장 깊은 것으로 보이는 골짜기를 찾아가는 여러 방법을 찾기 위해 사용하는 여러 방법이 있고, 대표적으로는 확률적 경사 하강법 즉, SGD가 있습니다.
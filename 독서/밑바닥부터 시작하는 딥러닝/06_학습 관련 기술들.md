이번 장에서는 가중치 매개변수의 최적값을 탐색하는 최적화와 가중치 매개변수 초깃값과 하이퍼파라미터를 설정하는 방법에 대해 설명 하겠습니다.

신경망 학습의 목적은 손실 함수의 값을 최대한 낮추는 매개변수의 최적값을 찾는 것인데 신경망의 최적화는 매우 어려운 문제고, 또 심층 신경망으로 갈수록 매개변수의 수가 엄청나게 많아져서 정답을 찾기는 거의 불가능합니다.

다음은 교재에서 인상 깊었던 예시인데요. 본론으로 들어가기 전에 먼저 말씀드리겠습니다.

모험가가 있습니다. 광활하고 메마른 산맥을 여행하면서 가장 깊고 깊은 골짜기를 찾아가려 합니다. 그런데 심지어 엄격한 제약이 있습니다. 지도를 보지 않고 눈도 가리고 깊은 곳을 찾아가야 합니다. 눈이 보이지 않으니 믿을 거라곤 발바닥으로 느껴지는 기울기뿐입니다. 지금 서 있는 곳보다 조금 더 기울어진 곳을 찾아 천천히 걸음을 옮기는 수밖에 없습니다.

우리도 최적값을 찾기 위해 이 모험가처럼 손실 함수가 가장 낮은 방향으로 매개변수를 조정해 나가야 합니다. 매우 어려운 문제입니다.

그래도  가장 깊거나 가장 깊은 것으로 보이는 골짜기를 찾아가는 여러 방법이 있고, 대표적으로는 확률적 경사 하강법 즉, SGD가 있습니다.

SGD는 기울어진 방향으로 일정 거리만 가는 단순한 방법으로 학습률과 손실함수의 기울기를 곱한 값을 가중치 매개변수에서 빼면서 값을 갱신합니다.

코드를 보시면 gradient 메서드의 파라미터와 기울기 값을 optimizer의 update 메서드에 전달하여 파라미터를 갱신합니다.

하지만 SGD는 단순한 만큼 단점도 있는데 비등방성 함수에서는 극명하게 나타납니다. 아래 함수를 그래프와 등고선으로 그려보면 가로로 길게 늘어진 형태이고 기울기를 그려보면 y축 방향은 크고 x축 방향은 매우 작습니다. 최솟값이 되는 장소는 x와 y가 0이 되는 지점이지만 기울기 대부분은 이 장소를 가리키지 않습니다.

이 함수에 SGD를 적용하면 이 그림과 같이 심하게 왔다 갔다 하는 모습을 보입니다. 상당히 비효율적이죠?

다음은 이 단점을 개선해 주는 모멘텀에 대해 설명 하겠습니다.

모멘텀은 운동량을 뜻하며 공이 그릇의 곡면을 따라 굴러 내려가는 것 처럼 움직여 손실 함수의 최저값을 찾기 위한 최적화 방법입니다.

모멘텀의 수식에서는 속도를 뜻하는 브이라는 변수가 새로 나오는데 알파 브이 항은 물체가 아무런 힘을 받지 않을때 공기저항이나 지면 마찰 처럼 서서히 하강시키는 역할을 합니다.

모멘컴 구현 코드를 살펴보면, 학습률과 모멘텀을 초기화하고 업데이트 메서드에서 브이 값이 없는 경우 넘파이 제로스 라이크 메서드로 0을 채웁니다.

그리고 모멘텀에 브이 값을 곱하고 학습률에 기울기를 곱한 값을 빼줍니다.  간단히 말하자면 이전 속도를 가능한 유지하면서 기울기의 변화 방향으로 점점 가속합니다. 만약 기울기의 방향이 반대로 바뀐다면 속도를 점점 줄이다가 반대 방향으로 천천히 움직입니다.

그림을 보면 실제 공이 굴러가는 것 처럼 움직여서 최저점을 찾아가는 것을 알 수 있습니다.

다음은 아다그레드입니다.

앞에서 모멘텀이 학습률을 그대로 두고 움직이려는 방향에 저항을 줬다면 아다그레드는 학습률을 조정하면서 학습 하는 방법입니다. 아답티브라는 이름과 같이 개별 매개변수에 적응적으로 학습률을 조정합니다.

수식이 점점 복잡해지는데요. 여기서는 에이치라는 변수가 새로 나옵니다. 이 변수는 기울기값이 커서 가장 많이 움직인 매개변수의 학습률을 낮추는 역할을 하는데, 상세한 내용은 코드를 보며 얘기할께요.

구현 코드에서 초기값으로 학습률을 받습니다. 에이치는 None 값으로 초기화 되네요.

업데이트 메서드에서 h값을 0으로 초기화 하고 기울기 값을 곱해서 더해줍니다. 이러면 기울기 값이 클 수록 에이치 값이 커질꺼에요.

매개변수를 갱신 할 때는 학습률과 기울기의 곱에 루트 에이치 값을 나눠줍니다. 그러면 에이치가 클 수록 갱신 강도가 낮아질꺼에요. 결국 이렇게 하면 매개변수의 원소 중에서 가장 많이 움직인 원소는 학습률이 낮아지게 됩니다.

그리고 수식에서 못 봤던 부분이 하나 있는데요 h값을 나누기 전에 1 마이너스 7 제곱 값을 더해줍니다. h에 만약 0이 담겨있다면 0으로 나누는 제로 디비전 에러가 발생하는데요 그 사태를 막아줍니다.

실제 알고리즘을 개발할 때도 한번씩 겪는 문제인데 0이 될 수 있는 값을 나눠야 할 때 이 내용을 참조하시면 좋을 것 같네요.

다음은 아다그레드를 이용한 최적화 갱신 경로입니다. 옆서 본 최적화 방법 중 가장 효율적으로 움직였네요. 처음엔 빠르게 움직이지만 h값으로 인해서 갱신 경로가 확 줄어들어서 지그제그로 움직이던 문제가 없어졌습니다.

마지막으로 아담입니다.

실제로 많이 사용했던 최적화 방법인데요. 논문에서는 데이터나 매개변수가 큰 문제와 고정되지 않은 목표와 잡음이 많거나 희박한 그라데이션이 있는 문제에 적합하다고 설명하고 있습니다. 

수식은 처음에 봤을 때는 복잡해 보여서 넘어가려고 했는데 보다보니 이해가 되는 부분이 있어서 간략하게 소개 드릴께요. 설명에 잘못된 부분이 있으면 말씀 해주세요.

우선 여기서는 학습률과 베타원, 베타투가 필요합니다 여기서는 디케이 레이트 즉 감쇠율입니다.. 베타원과 베타투는 각각 0.9와 0.999일 때 대부분의 문제에서 좋은 결과가 나온다고 하네요.

1차 모멘트 벡터, 2차 모멘트 백터와 타임스탭, t값을 0으로 초기화하고 세타 t값이 수렴될 때 까지 반복합니다.

1차 모멘트 m에는 베타원에 이전 m값을 곱한 뒤 1 마이너스 베타원에 기울기를 곱한 값을 더해줍니다. 간단하게 생각한다면 이전 m값에 감쇠율을 곱하므로 조금씩 이전 m값을 잊습니다.

2차 모멘트 v는 기울기의 제곱을 곱하고 나중에 학습률에 제곱근값을 나누므로 아다그레드와 같습니다. 아다그레드와 유사한 역할을 하겠죠?

그리고 각 모멘트 값에 편향 보정을 해 주는데요. 모멘텀 값이 0으로 초기화 되는 것을 방지하기 위함이라고 합니다.

아담을 이용해서 최적화를 갱신한 결과 모멘텀과 유사한 패턴이지만 학습의 갱신 강도를 적응적으로 조정하므로 좌우 흔들림이 적은 것을 볼 수 있습니다.

앞서 설명한 최적화 방법을 선택하는데 정답은 없습니다. 각자 장단이 있고 앞서 가장 안 좋은 성능을 보였던 SGD도 아직 많은 연구에서 사용하고 있다고 합니다.

https://arxiv.org/pdf/1412.6980.pdf
이번 장에서는 가중치 매개변수의 최적값을 탐색하는 최적화와 가중치 매개변수 초깃값과 하이퍼파라미터를 설정하는 방법에 대해 설명 하겠습니다.

신경망 학습의 목적은 손실 함수의 값을 최대한 낮추는 매개변수의 최적값을 찾는 것인데 신경망의 최적화는 매우 어려운 문제고, 또 심층 신경망으로 갈수록 매개변수의 수가 엄청나게 많아져서 정답을 찾기는 거의 불가능하다고 생각됩니다.

다음은 교재에서 인상 깊었던 예시인데요.

최적값을 찾기 위한 활동을 모험에 비유했습니다. 아무것도 보이지 않는 상태에서 조금 더 아래로 기울어진 곳으로 찾아가는 것이 정말 적절한 비유였습니다.

우리도 최적값을 찾기 위해 이 모험가처럼 손실 함수가 가장 낮은 방향으로 매개변수를 조정해 나가야 하는데요. 매우 어려운 문제입니다.

그래도  가장 깊거나 가장 깊은 것으로 보이는 골짜기를 찾아가는 여러 방법이 있고, 대표적으로는 확률적 경사 하강법 즉, SGD가 있습니다.

SGD는 기울어진 방향으로 일정 거리만 가는 단순한 방법이고 학습률과 손실함수의 기울기를 곱한 값을 가중치 매개변수에서 빼면서 값을 갱신합니다.

코드를 보시면 그라디언트 메서드의 파라미터와 기울기 값을 옵티마이저의 업데이트 메서드에 전달하여 파라미터를 갱신합니다.

하지만 SGD는 단순한 만큼 단점도 있는데 비등방성 함수에서는 그 단점이 극명하게 나타납니다.

아래 함수를 그래프와 등고선으로 그려보면 가로로 길게 늘어진 형태고 기울기를 그려보면 y축 방향은 크고 x축 방향은 매우 작습니다. 최솟값이 되는 장소는 x와 y가 0이 되는 지점이지만 기울기 대부분은 이 장소를 가리키지 않습니다.

이 함수에 SGD를 적용하면 아래 그림과 같이 심하게 왔다 갔다 하는 모습을 보입니다. 상당히 비효율적입니다.

다음은 이 단점을 개선해 주는 모멘텀에 대해 설명 하겠습니다.

모멘텀은 운동량을 뜻하는데 공이 그릇의 곡면을 따라 구르는것 처럼 움직여 손실 함수의 최저값을 찾아가는 최적화 방법입니다.

모멘텀의 수식에서는 속도를 뜻하는 브이라는 변수가 새로 나오는데 알파 브이 항은 물체가 아무런 힘을 받지 않을때 공기저항이나 지면 마찰 처럼 공을 서서히 하강시키는 역할을 합니다.

모멘컴 구현 코드를 살펴보면, 학습률과 모멘텀을 초기화하고 업데이트 메서드에서 브이 값이 없는 경우 넘파이 제로스 라이크 메서드로 0을 채웁니다.

그리고 모멘텀에 브이 값을 곱하고 학습률에 기울기를 곱한 값을 빼줍니다.  간단히 말하자면 이전 속도를 가능한 유지하면서 기울기의 변화 방향으로 점점 가속합니다. 만약 기울기의 방향이 반대로 바뀐다면 속도를 점점 줄이다가 반대 방향으로 천천히 움직입니다.

그림을 보면 실제 공이 구르는것 처럼 움직여서 최저점을 찾아가는 것을 알 수 있습니다.

다음은 아다그레드입니다.

앞에서 모멘텀이 학습률을 그대로 두고 움직이려는 방향에 저항을 줬다면 아다그레드는 학습률을 조정하면서 학습 하는 방법입니다. 아답티브라는 이름과 같이 개별 매개변수에 적응적으로 학습률을 조정합니다.

수식이 점점 복잡해지는데요. 여기서는 에이치라는 변수가 새로 나옵니다. 이 변수는 기울기값이 커서 가장 많이 움직인 매개변수의 학습률을 낮추는 역할을 하는데, 상세한 내용은 코드를 보며 얘기할께요.

구현 코드에서 초기값으로 학습률을 받습니다. 에이치는 논 값으로 초기화 되네요.

업데이트 메서드에서 h값을 0으로 초기화 하고 기울기 값을 곱해서 더해줍니다. 이러면 기울기 값이 클 수록 에이치 값이 커질껍니다.

매개변수를 갱신 할 때는 학습률과 기울기의 곱에 루트 에이치 값을 나눠줍니다. 그러면 에이치가 클 수록 갱신 강도가 낮아질껍니다. 결국 이렇게 하면 매개변수의 원소 중에서 가장 많이 움직인 원소는 학습률이 낮아지게 됩니다.

그리고 수식에서 못 봤던 부분이 하나 있는데요 h값을 나누기 전에 1 마이너스 7 제곱 값을 더해줍니다. h에 만약 0이 담겨있다면 0으로 나누는 제로 디비전 에러가 발생하는데 그 사태를 막아줍니다.

실제 알고리즘을 개발할 때도 한번씩 겪는 문젠데 0이 될 수 있는 값을 나눠야 할 때 이 내용을 참조하시면 좋을 것 같네요.

다음은 아다그레드를 이용한 최적화 갱신 경로입니다. 앞서 본 최적화 방법 중에 가장 효율적으로 움직였네요. 처음엔 빠르게 움직이지만 h값으로 인해서 갱신 경로가 확 줄어들어서 지그제그로 움직이던 문제가 없어졌습니다.

마지막으로 아담입니다.
https://arxiv.org/pdf/1412.6980.pdf

실제로 많이 사용했던 최적화 방법인데요. 논문에서는 데이터나 매개변수가 큰 문제와 고정되지 않은 목표와 잡음이 많거나 희박한 그라데이션이 있는 문제에 적합하다고 설명하고 있습니다. 

![](attachments/Pasted%20image%2020231110212723.png)

수식은 처음에 봤을 때는 복잡해 보여서 넘어가려고 했는데 보다보니 이해가 되는 부분이 있어서 간략하게 소개 드리겠습니다. 설명에 잘못된 부분이 있으면 말씀 해주세요.

![](attachments/Pasted%20image%2020231110212647.png)

우선 여기서는 학습률과 베타원, 베타투가 필요합니다. 디케이 레이트 즉 감쇠율입니다.. 베타원과 베타투는 각각 0.9와 0.999일 때 대부분의 문제에서 좋은 결과가 나온다고 하네요.

1차 모멘트 벡터, 2차 모멘트 백터와 타임스탭, t값을 0으로 초기화하고 세타 t값이 수렴될 때 까지 반복합니다.

1차 모멘트 m에는 베타원에 이전 m값을 곱한 뒤 1 마이너스 베타원에 기울기를 곱한 값을 더해줍니다. 간단하게 생각한다면 이전 m값에 감쇠율만큼 작게 만드니까 조금씩 이전 m값을 잊습니다.

2차 모멘트 v는 기울기의 제곱을 곱하고 나중에 학습률에 제곱근값을 나누니까 아다그레드와 같습니다. 실제로 아다그레드와 유사한 역할을 하겠죠?

그리고 각 모멘트 값에 편향 보정을 해 주는데요. 모멘텀 값이 0으로 초기화 되는 것을 방지하기 위해서라고 합니다.

아담을 이용해서 최적화를 갱신한 결과 모멘텀하고 유사한 패턴이지만 학습의 갱신 강도를 적응적으로 조정하므로 좌우 흔들림이 적은 것을 볼 수 있습니다.

앞서 설명한 최적화 방법을 선택하는데 정답은 없습니다. 각자 장단이 있고 앞서 가장 안 좋은 성능을 보였던 SGD도 아직 많은 연구에서 사용하고 있다고 합니다.

손글씨 숫자 인식을 대상으로 네 기법을 비교한 그래프입니다. 각 층이 100개의 뉴런으로 구성된 5층 신경망에서 ReLU를 활성화 함수로 사용해 측정되었습니다.

SGD를 제외한 세 기법의 진도는 비슷하지만 아다그레드가 조금 더 빠른 것으로 보입니다.


다음은 가중치의 초기값에 관한 내용입니다.

가중치의 초기값 설정은 신경망 학습에서 특히 중요한데 초기값을 어떻게 설정하느냐에 따라서 학습의 성패가 나뉘는 경우가 자주 있다고 합니다.

일반적으로 오버피팅을 억제하기 위해 가중치 감소 기법을 사용하고 가중치 매개변수의 값이 작아지도록 학습해서 오버피팅이 일어나지 않게 합니다.

일반적으로 정규분포값을 0.01배 한 값처럼 작은 값을 주로 사용하는데 그렇다고 또 0으로 설정하면 학습이 재대로 되지 않으니까 주의해야 됩니다.

초깃값을 0으로 두게 되면 오차역전파법에서 모든 가중치의 값이 똑같이 갱신되니까 가중치를 여러 개 갖는 의미가 없어집니다. 그래서 작은 값으로 하되 무작위로 설정해야 합니다.

가중치의 초기값에 따른 은닉층의 활성화 값 분포에 대해 말씀 드리겠습니다.

코드를 보면 은닉층이 5개 있고, 각 층의 뉴런은 100개씩입니다. 데이터는 1000개의 데이터를 정규분포로 무작위 생성하여 흘렸고 활성화 함수는 시그모이드 함수를 이용했습니다.

가중치에 따른 활성화 값들의 분포 변화를 유심히 봐주시면 되겠습니다.

먼저 표준편차가 1인 정규분포를 사용하면 각 층의 활성화 값이 0과 1에 치우치게 됩니다.

시그모이드 함수는 출력이 0에 가까워지거나 1에 가까워지면 미분이 0에 가까워지고 기울기 값이 점점 작아지다가 사라지는 기울기 소실 문제가 발생된겁니다.


다음은 가중치의 표준편차를 0.01로 바꿨을 때의 활성화 값 분포입니다.

이번에는 0.5 부근에 집중되었습니다. 기울기 소실 문제는 없지만 다수의 뉴런이 같은 값을 출력하게되서 뉴런 여러개를 둔 의미가 없어졌습니다. 표현력이 제한되었다라고 말하기도 합니다.


사비에르 초깃값을 써봤습니다. 일반적인 딥러닝 프레임워크들이 표준적으로 이용하고 있다고 합니다.

포준 편차의 값을 노드의 개수의 미분 분의 1으로 설정하는 것으로 앞 층에 노드가 많을수록 대상 노드의 초깃값으로 설정하는 가중치가 좁게 퍼집니다.

사비에르 초깃값을 사용한 결과 층이 깊어지면 형태가 다소 일그러지지만 다른 방식에 비해 넓게 분포된 것이 보입니다.

하지만 ReLU를 사용할 때는 ReLU에 특화된 히 초기값을 사용하라고 권장됩니다.

히 초기값은 앞 계층의 노드가 n개일 때 표준편차가 루트 n분의 2인 정규분포를 사용하며 ReLU는 음의 영역이 0이라서 활성화 값을 더 넓게 분포 시키기 위해 2배의 계수가 필요한 것으로 이해할 수 있습니다.

렐루 함수를 사용 했을 때 가중치 초깃값에 따른 활성화값 분포 변화입니다.

표준편차가 0.01일 때는 아주 작은 값으로 수렴합니다. 사비에르 초깃값은 층이 깊어지면서 치우침이 조금씩 커져 기울기 소실 문제를 일으킬 가능성이 높습니다.

마지막으로 히 초기값은 모든 층에서 균일하게 분포되어 역전파에서도 적절한 값이 나올 것으로 기대됩니다.

실제 데이터로 학습을 해 보면 표준편차 0.01을 사용 했을 때 학습이 전혀 되지 않습니다.

사비에르와 히 초기값 모두 학습이 잘 되지만 히 초기값이 좀 더 빠르게 학습 되는 것을 확인 할 수 있습니다.

위의 결과에서처럼 활성화 함수로 렐루를 사용할 때는 히 초기값을 사용하고 시그모이드나 하이퍼볼릭 탄젠트를 사용할 때는 사비에르 초기값을 사용하는게 모범 사례입니다.

배치 정규화

앞에서는 가중치의 초기값을 적절히 설정해서 각 층의 활성화 값 분포가 적당히 퍼지도록 했다면 배치 정규화는 각 층이 활성화를 적당히 퍼트리도록 강제하는 방법입니다.

정규화는 학습 속도 개선, 초깃값에 크게 의존하지 않음, 오버피팅의 억제와 같이 딥러닝에 있어서 골치아픈 문제점들을 해결 해 줍니다.

배치 정규화를 위해서는 그림과 같이 신경망 사이에 배치 정규화 계층을 삽입합니다.

정규화 계층에서는 미니배치를 정규화하고 적절한 평균과 표준편차로 조정 해 줍니다.

yi ← γ * ^xi + β

해당 식에서 감마가 확대, 베타가 이동을 담당하며 처음에는 감마가 1, 베타가 0으로 시작해 적합한 값으로 조정됩니다.

역전파 유도는..

배치 정규화 계층을 사용할 때와 사용하지 않을 때 그래프와 같이 극명한 학습속도 차이가 보입니다.

그리고 초깃값 분포를 다양하게 줬을 때에도 거의 모든 경우에 배치 정규화를 사용한 경우 학습 속도가 빠릅니다. 일부 초깃값에 문제가 있는 경우 학습이 전혀 안되는 경우도 있습니다.

기계 학습에서는 오버피팅이 문제가 되는 경우가 많습니다. 복잡하고 표현력이 높은 모델을 만드는 것도 중요하지만 범용적인 성능을 위해 오버피팅을 억제하는 기술도 매우 중요합니다.

오버피팅은 주로 매개변수가 많고 표현력이 높은 모델에서, 그리고 훈련 데이터가 적을 때 주로 발생됩니다.

아래 예제는 두 요건을 일부러 충족해서 오버피팅을 일으키고 있습니다.

학습 데이터 수를 300개로 줄이고 7층 네트워크를 사용했습니다.

이 경우 그래프와 같이 훈련 데이터의 정확도는 100에폭부터 거의 100프로지만 시험데이터는 70프로에서 유지되는 것을 볼 수 있습니다.

오버피팅을 억제하는 기술 중 하나로 가중치 감소가 있습니다.

가중치 매개변수의 크기가 커져서 발생하는 오버피팅을 억제하기 위해 큰 가중치에 대해 패널티를 부과하는 방식입니다.

가중치의 제곱 노름을 손실함수에 더하여 가중치가 커지는 것을 억제할 수 있습니다.  ...

L2 노름은 각 원소의 제곱을 모두 더한 값입니다.

가중치 감소를 이용해 정확도 추이를 확인 해 본 결과 훈련 데이터와 시험 데이터의 차이가 줄어든 것을 볼 수 있습니다. 그런데 테스트 데이터의 정확도가 이전과 큰 차이가 없는 것으로 봐서 오버피팅 억제의 효과를 재대로 보지는 못 한 것 같네요..

그런데 신경망 모델이 복잡해지면 가중치 감소만으로는 대응이 어려워서 드롭아웃 기법을 사용하기도 합니다.

드롭아웃은 뉴런을 임의로 삭제하면서 학습하는 방법으로 훈련 때 데이터를 흘릴 때마다 삭제할 뉴런을 무작위로 삭제하고 시험때는 모든 뉴런에 신호를 전달합니다.

앙상블 학습을 이용하는 것 처럼 매번 다른 모델을 학습하여 평균을 내는것과 같은 효과를 기대할 수 있습니다.

원칙적으로는 훈련 때 삭제 안 한 비율을 곱하여 출력하지만 실제 딥러닝 프레임워크에서도 삭제 비율은 곱하지 않으니 해당 로직은 생략해도 괜찮습니다.

함수는 간단합니다. 초기화 때 드롭아웃 비율을 지정하고 순전파를 할 때마다 그 비율만큼 마스크를 만들어 신호를 삭제합니다. 훈련이 아닐때는 뉴런에 1 마이너스 드롭아웃 비율만큼을 곱해줍니다.

역전파때도 같은 마스크를 이용해 신호를 삭제 해 줍니다.

드롭아웃을 이용하면 그래프와 같은 결과를 얻을 수 있습니다. 그런데 300 에포크가 진행 될 때는 훈련과 테스트 결과의 차이도 유사하고 오히려 전체적으로 정확도가 떨어지는 결과입니다.

교재에서는 특별한 언급이 없었지만 이론과 실제가 일부 격차가 있는 것으로 보입니다.

신경망에는 뉴런 수, 배치크기, 학습률, 가중치 감소와 같이 다수의 하이퍼파라미터가 있는데 이를 결정하는 데 많은 시행착오를 겪기도 합니다. 아래 내용은 하이퍼파라미터를 가능한 효율적으로 탐색할 수 있는 방법입니다.

하이퍼 파라미터에 따른 성능을 평가 할 때 시험 데이터를 사용하면 시험 데이터에 오버피팅 될 수 있으므로 하이퍼파라미터 성능 평가용 데이터셋을 이용해야 하는데 일반적으로 검증데이터라고 부릅니다.

엠니스트 데이터셋은 훈련데이터와 시험데이터로만 분리되어 있으니 훈련 데이터 중 일부를 검증 데이터로 분리해서 사용 할 수 있습니다.

코드에서는 셔플 데이터셋 함수를 이용해 데이터를 뒤섞고 0.2 비율만큼 슬라이스 해 줬습니다.

하이퍼파라미터를 최적화 할 때 일반적으로 그리드서치로 규칙적인 탐색을 하는 것 보다 무작위로 샘플링해 탐색하는 편이 더 좋은 결과를 내는 것으로 알려져 있는데 하이퍼파라미터마다 정확도에 미치는 영향이 서로 다르기 때문입니다.

따라서 하이퍼파라미터의 범위를 0.001~1000같이 로그스케일 범위에서 대략적으로 지정하고 최적 값이 존재하는 범위를 조금씩 줄여가며 탐색 하는 것이 좋습니다.

학습을 위한 에폭을 작게 해서 평가에 걸리는 시간을 단축하여 안될 것 같은 값은 빨리 포기하고 범위를 좁혀갑니다.

아래 코드에서는 가중치 감소와 학습률의 범위를 지정 후 랜덤하게 추출해서 정확도를 실험했습니다.

여기서 베스트 값의 하이퍼파라미터를 보고 범위를 줄여가며 축소된 범위로 같은 작업을 반복할 수 있습니다.